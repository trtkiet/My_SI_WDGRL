from mpmath import mp
import numpy as np
import torch
from typing import List
from layers import *
from operations import *
import math
import time

mp.dps = 500
def gen_data(mu: float, delta: List[int], n: int, d: int):
    mu = np.full((n, d), mu, dtype=np.float64)
    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))
    X = mu + noise
    labels = np.zeros(n)
    if len(delta) == 1:
        n_anomalies = int(n * 0.05)
        idx = np.random.choice(n, n_anomalies, replace=False)
        X[idx] = X[idx] + delta[0]
        if delta[0] != 0:
            labels[idx] = np.ones(n_anomalies)
    else:
        # In this case, we generate data for source domain.
        # 5% of the data is abnormal.
        # Anomalies are generated by randomly adding deltas to the data.
        n_anomalies = int(n * 0.05)
        idx = np.random.choice(n, n_anomalies, replace=False)
        if 0 in delta: 
            delta.pop(delta.index(0))
        if len(delta) != 0:
            split_points = sorted(np.random.choice(range(1, len(idx)), len(delta) - 1, replace=False))
            segments = np.split(idx, split_points)
            for i, segment in enumerate(segments):
                X[segment] = X[segment] + delta[i]
            labels[idx] = 1
    return X, labels

def intersect(itv1, itv2):
    # print(itv1, itv2)
    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]
    if itv[0] > itv[1]:
        return None    
    return itv

def solve_linear_inequality(u, v): #u + vz < 0
    u = float(u)
    v = float(v)
    # print(u, v)
    if (v > -1e-16 and v < 1e-16):
        if (u <= 0):
            return [-np.inf, np.inf]
        else:
            print('error', u, v)
            return None
    if (v < 0):
        return [-u/v, np.inf]
    return [-np.inf, -u/v]


def get_dnn_interval(x, a, b, list_layers):
    itv = np.asarray([-np.inf, np.inf])
    itv = cuda.to_device(itv)
    a = cuda.to_device(a)
    b = cuda.to_device(b)
    x = cuda.to_device(x)
    for name, param in list_layers:
        if name == 'Linear Weight':
            a, b, x = LinearWeight(a, b, x, param)
        elif name == 'Linear Bias':
            a, b, x = LinearBias(a, b, x, param)
        elif name == 'ReLU':
            a, b, x, itv = Relu(a, b, x, itv)
    itv = itv.copy_to_host()
    a = a.copy_to_host()
    b = b.copy_to_host()
    return itv, a, b

def get_alpha_percent_greatest(X, alpha):
    return np.argsort(X)[-int(alpha*len(X))]

def AE_AD(Xs_hat, Xt_hat, X_tilde, alpha):
    X = np.concatenate((Xs_hat, Xt_hat), axis=0)
    reconstruction_loss = np.abs(X - X_tilde).sum(axis=1)
    #Take 5% largest in reconstruction loss
    O = np.argsort(reconstruction_loss)[-int(alpha*len(reconstruction_loss)):]
    O = [i - Xs_hat.shape[0] for i in O if i >= Xs_hat.shape[0]]
    return np.sort(O)

def get_ad_interval(X, X_hat, X_tilde, reconstruction_loss, a, b, wdgrl, ae, alpha):
    itv = [-np.inf, np.inf]
    sub_itv, u, v = get_dnn_interval(X, a, b, wdgrl)
    itv = intersect(itv, sub_itv)
    sub_itv, p, q = get_dnn_interval(X_hat, u, v, ae)
    itv = intersect(itv, sub_itv)
    s = np.zeros((X_hat.shape[0], X_hat.shape[1]))
    for i in range(X_hat.shape[0]):
        for d in range(X_hat.shape[1]):
            if X_tilde[i, d] < X_hat[i, d]:
                itv = intersect(itv, solve_linear_inequality(p[i, d] - u[i, d], q[i, d] - v[i, d]))
            else:
                itv = intersect(itv, solve_linear_inequality(u[i, d] - p[i, d], v[i, d] - q[i, d]))
            s[i, d] = np.sign(X_tilde[i, d] - X_hat[i, d])
    
    
    pivot = get_alpha_percent_greatest(reconstruction_loss, alpha)
    A = np.zeros((X_hat.shape[0], 1))
    B = np.zeros((X_hat.shape[0], 1))
    for i in range(u.shape[0]):
        for d in range(u.shape[1]):
            A[i] += s[i, d]*(p[i, d] - u[i, d])
            B[i] += s[i, d]*(q[i, d] - v[i, d])
    for i in range(X_hat.shape[0]):
        if reconstruction_loss[i] < reconstruction_loss[pivot]:
            itv = intersect(itv, solve_linear_inequality(A[i] - A[pivot], B[i] - B[pivot]))
        else:
            itv = intersect(itv, solve_linear_inequality(A[pivot] - A[i], B[pivot] - B[i]))
    return itv

def compute_yz(zk, a, b):
    Xz = a + b*zk
    return Xz

def parametric_si(Xz, a, b, zk, wdgrl, ae, np_wdgrl, np_ae, alpha, ns, nt):
    Xz_hat = wdgrl.extract_feature(torch.DoubleTensor(Xz).to(wdgrl.device)).cpu().numpy()
    Xz_tilde = ae.forward(torch.DoubleTensor(Xz_hat).to(ae.device)).cpu().numpy()
    reconstruction_loss = ae.reconstruction_loss(torch.DoubleTensor(Xz_hat).to(ae.device))
    reconstruction_loss = [i.item() for i in reconstruction_loss]
    Oz = AE_AD(Xz_hat[:ns], Xz_hat[ns:], Xz_tilde, alpha)
    itv = get_ad_interval(Xz, Xz_hat, Xz_tilde, reconstruction_loss, a, b, np_wdgrl, np_ae, alpha)
    if zk < itv[0] or zk > itv[1]:
        print('error', zk, itv)
    return itv[1] - min(zk, itv[1]), Oz


def run_parametric_si(a, b, threshold, wdgrl, ae, np_wdgrl, np_ae, alpha, ns, nt):
    zk = threshold[0]

    list_zk = [zk]
    list_Oz = []

    while zk < threshold[1]:
        Xz = compute_yz(zk, a, b)
        skz, Oz = parametric_si(Xz, a, b, zk, wdgrl, ae, np_wdgrl, np_ae, alpha, ns, nt)
        zk = zk + skz + 1e-3 
        # zk = min(zk, threshold)
        list_zk.append(zk)
        list_Oz.append(Oz)
        print(f'intervals: {zk-skz-1e-3} - {zk -1e-3}')
        print(f'Anomaly index: {Oz}')
        print('-------------')
    return list_zk, list_Oz
        
def cdf(mu, sigma, list_zk, list_Oz, etajTX, O):
    numerator = 0
    denominator = 0
    for each_interval in range(len(list_zk) - 1):
        al = list_zk[each_interval]
        ar = list_zk[each_interval + 1] - 1e-3

        if (np.array_equal(O, list_Oz[each_interval]) == False):
            continue

        denominator = denominator + mp.ncdf((ar - mu)/sigma) - mp.ncdf((al - mu)/sigma)
        if etajTX >= ar:
            numerator = numerator + mp.ncdf((ar - mu)/sigma) - mp.ncdf((al - mu)/sigma)
        elif (etajTX >= al) and (etajTX< ar):
            numerator = numerator + mp.ncdf((etajTX - mu)/sigma) - mp.ncdf((al - mu)/sigma)
    # print(f'numerator: {numerator}')
    # print(f'denominator: {denominator}')
    if denominator != 0:
        return float(numerator/denominator)
    else:
        return None

def truncated_cdf(etajTy, mu, sigma, left, right):
    numerator = mp.ncdf((etajTy - mu) / sigma) - mp.ncdf((left - mu) / sigma)
    denominator = mp.ncdf((right - mu) / sigma) - mp.ncdf((left - mu) / sigma)
    # print(numerator/denominator)
    if denominator != 0:
        return float(numerator/denominator)
    else:
        return None
    

